#Imported this code from Google Collabs
!pip install praw
!pip install pandas
!pip install nltk
!pip install matplotlib
!pip install seaborn
!pip install wordcloud

from collections import UserList
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from wordcloud import WordCloud
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import praw
import pandas as pd
import matplotlib.pyplot as plt
import nltk
import csv
import seaborn as sns
nltk.download('vader_lexicon')
nltk.download('punkt')

reddit = praw.Reddit(client_id="", client_secret="", user_agent="")
                                       
subreddit = reddit.subreddit("depression")
top_posts= subreddit.top(limit=50)
posts=[]
for post in top_posts:
    posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])

commentsandposts=[]
posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])
for index, rows in posts.iterrows():
  if "imgur.com" in rows['url']:
    continue
  submission = reddit.submission(url=rows['url'])
  submission.comment_sort = "top"
  commentsandposts.append([rows['id'], list(submission.comments)])

commenttext=[]
posttext=[]
for index in range(len(commentsandposts)):
  commentidlist=commentsandposts[index]
  postid= commentidlist[0]
  commentid=commentidlist[1]
  posttext.append(reddit.submission(id=postid).selftext)
  for index in range(len(commentid)):
    commenttext.append(commentid[index].body)

sentimentscorescomments=[]
sentimentscoresposts=[]
frequencycommentsten=[]
frequencypoststen=[]
sia = SentimentIntensityAnalyzer()
for index in range (len(commenttext)):
  sentimentscorescomments.append(sia.polarity_scores(commenttext[index]))
  words= nltk.word_tokenize(commenttext[index])
  words = [word for word in words if word.isalpha()]
  stop_words = set(stopwords.words('english'))
  words = [w for w in words if not w in stop_words]
  fd = nltk.FreqDist(words)
  frequencycommentsten.append(fd)
for index in range (len(posttext)):
  sentimentscoresposts.append(sia.polarity_scores(posttext[index]))
  words= nltk.word_tokenize(posttext[index])
  words = [word for word in words if word.isalpha()]
  stop_words = set(stopwords.words('english'))
  words = [w for w in words if not w in stop_words]
  fd = nltk.FreqDist(words)
  frequencypoststen.append(fd)

totalcommentnegscore=0
totalpostnegscore=0
totalcommentposscore=0
totalpostposscore=0

for i in range(len(sentimentscorescomments)):
  totalcommentnegscore+=sentimentscorescomments[i]['neg']
  totalcommentposscore+=sentimentscorescomments[i]['pos']

averagecommentneg=totalcommentnegscore/len(sentimentscorescomments)
averagecommentpos=totalcommentposscore/len(sentimentscorescomments)

for i in range(len(sentimentscoresposts)):
  totalpostnegscore+=sentimentscoresposts[i]['neg']
  totalpostposscore+=sentimentscoresposts[i]['pos']

averagepostneg=totalpostnegscore/len(sentimentscoresposts)
averagepostpos=totalpostposscore/len(sentimentscorescomments)

dictionaryfcs=[]
dictionaryfps=[]
for index in range(len(frequencycommentsten)):
  dictionarycommentsten=dict(frequencycommentsten[index])
  dictionaryfcs.append(dictionarycommentsten)
for index in range(len(frequencypoststen)):
  dictionarypoststen=dict(frequencypoststen[index])
  dictionaryfps.append(dictionarypoststen)

mergedcomments = {}
mergedposts={}
for index in range(len(dictionaryfcs)):
  mergedcomments=mergedcomments+ Counter(dictionaryfcs[index])
for index in range(len(dictionaryfps)):
  mergedposts=mergedposts + Counter(dictionaryfps[index])

wordcloudc = WordCloud(background_color="white",width=1000,height=1000, max_words=100, normalize_plurals=False).generate_from_frequencies(mergedcomments)
plt.savefig('Word Cloud Comment Body.png')

plt.figure(figsize=(20,20))
plt.imshow(wordcloudc)
plt.savefig('Word Cloud Post Body.png')

wordcloudp = WordCloud(background_color="white",width=1000,height=1000, max_words=100, normalize_plurals=False).generate_from_frequencies(mergedposts)
plt.figure(figsize=(20,20))
plt.imshow(wordcloudp)

mergedcommentsstrimmed={key:val for key, val in mergedcomments.items() if val > 300}
plotdata=pd.Series(mergedcommentsstrimmed)
fig, ax = plt.subplots(figsize=(30,20))
all_plot = sns.barplot(x=plotdata.index, y=plotdata.values, ax=ax)
plt.xticks(rotation=30);
plt.savefig('Histogram.png')
